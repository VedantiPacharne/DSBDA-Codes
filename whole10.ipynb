{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba8d69a-781f-4033-9171-2aed70647d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine', 'learning', 'is', 'the', 'science', 'of', 'getting', 'computers', 'to', 'learn', 'from', 'data', 'without', 'being', 'explicitly', 'programmed', '.', 'It', 'is', 'a', 'branch', 'of', 'artificial', 'intelligence', 'based', 'on', 'the', 'idea', 'that', 'systems', 'can', 'learn', 'from', 'data', ',', 'identify', 'patterns', 'and', 'make', 'decisions', 'with', 'minimal', 'human', 'intervention', '.']\n",
      "[('Machine', 'NN'), ('learning', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('science', 'NN'), ('of', 'IN'), ('getting', 'VBG'), ('computers', 'NNS'), ('to', 'TO'), ('learn', 'VB'), ('from', 'IN'), ('data', 'NNS'), ('without', 'IN'), ('being', 'VBG'), ('explicitly', 'RB'), ('programmed', 'VBN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('a', 'DT'), ('branch', 'NN'), ('of', 'IN'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('based', 'VBN'), ('on', 'IN'), ('the', 'DT'), ('idea', 'NN'), ('that', 'IN'), ('systems', 'NNS'), ('can', 'MD'), ('learn', 'VB'), ('from', 'IN'), ('data', 'NNS'), (',', ','), ('identify', 'NN'), ('patterns', 'NNS'), ('and', 'CC'), ('make', 'VB'), ('decisions', 'NNS'), ('with', 'IN'), ('minimal', 'JJ'), ('human', 'JJ'), ('intervention', 'NN'), ('.', '.')]\n",
      "['Machine', 'learning', 'science', 'getting', 'computers', 'learn', 'data', 'without', 'explicitly', 'programmed', 'branch', 'artificial', 'intelligence', 'based', 'idea', 'systems', 'learn', 'data', 'identify', 'patterns', 'make', 'decisions', 'minimal', 'human', 'intervention']\n",
      "['machin', 'learn', 'scienc', 'get', 'comput', 'learn', 'data', 'without', 'explicitli', 'program', 'branch', 'artifici', 'intellig', 'base', 'idea', 'system', 'learn', 'data', 'identifi', 'pattern', 'make', 'decis', 'minim', 'human', 'intervent']\n",
      "['Machine', 'learning', 'science', 'getting', 'computer', 'learn', 'data', 'without', 'explicitly', 'programmed', 'branch', 'artificial', 'intelligence', 'based', 'idea', 'system', 'learn', 'data', 'identify', 'pattern', 'make', 'decision', 'minimal', 'human', 'intervention']\n",
      "     allows       and       are  artificial    branch  computers      data  \\\n",
      "0  0.000000  0.000000  0.000000    0.306504  0.403016   0.000000  0.000000   \n",
      "1  0.389888  0.000000  0.000000    0.000000  0.000000   0.389888  0.296520   \n",
      "2  0.000000  0.385323  0.385323    0.293048  0.000000   0.000000  0.293048   \n",
      "\n",
      "   evolving    fields      from  intelligence        is        it     learn  \\\n",
      "0  0.000000  0.000000  0.000000      0.306504  0.403016  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.389888      0.000000  0.000000  0.389888  0.389888   \n",
      "2  0.385323  0.385323  0.000000      0.293048  0.000000  0.000000  0.000000   \n",
      "\n",
      "   learning   machine        of   science        to  \n",
      "0  0.403016  0.403016  0.403016  0.000000  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.389888  \n",
      "2  0.000000  0.000000  0.000000  0.385323  0.000000  \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "document=\"\"\"Machine learning is the science of getting computers to learn from data without being explicitly programmed.\n",
    "It is a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"\"\"\n",
    "\n",
    "tokens=word_tokenize(document)\n",
    "print(tokens)\n",
    "\n",
    "posts=pos_tag(tokens)\n",
    "print(posts)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "filtered=[word for word in tokens if word.lower() not in stop and word.isalpha()]\n",
    "print(filtered)\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "stemmer=PorterStemmer()\n",
    "stemmed=[stemmer.stem(word) for word in filtered]\n",
    "print(stemmed)\n",
    "\n",
    "lem=WordNetLemmatizer()\n",
    "lems=[lem.lemmatize(word) for word in filtered]\n",
    "print(lems)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "documents = [\n",
    "    \"Machine learning is a branch of artificial intelligence.\",\n",
    "    \"It allows computers to learn from data.\",\n",
    "    \"Artificial intelligence and data science are evolving fields.\",\n",
    "]\n",
    "\n",
    "\n",
    "vectorizer=TfidfVectorizer()\n",
    "matrix=vectorizer.fit_transform(documents)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "dataframe=pd.DataFrame(matrix.toarray(),columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(dataframe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4532023b-33f1-4660-a4bc-20899861c1da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
